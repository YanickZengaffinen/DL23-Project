{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3ce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torchattacks import PGD\n",
    "import random\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import Omniglot\n",
    "from PIL import Image\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Will use:\", device)\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8780cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b29600a",
   "metadata": {},
   "source": [
    "## Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fae8e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypnettorch.data import FashionMNISTData, MNISTData\n",
    "from hypnettorch.data.dataset import Dataset\n",
    "from hypnettorch.mnets import LeNet\n",
    "from hypnettorch.mnets.resnet import ResNet\n",
    "from hypnettorch.mnets.mlp import MLP\n",
    "from hypnettorch.hnets import HMLP\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import learn2learn as l2l\n",
    "import copy\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load Min-image net\n",
    "mini_train = l2l.vision.datasets.MiniImagenet(root=data_dir, mode='train', download=True)\n",
    "mini_train = l2l.data.MetaDataset(mini_train)\n",
    "\n",
    "mini_valid = l2l.vision.datasets.MiniImagenet(root=data_dir, mode='validation', download=True)\n",
    "mini_valid = l2l.data.MetaDataset(mini_valid)\n",
    "\n",
    "mini_test = l2l.vision.datasets.MiniImagenet(root=data_dir, mode='test', download=True)\n",
    "mini_test = l2l.data.MetaDataset(mini_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf2a597",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a DataLoader for batching and shuffling the data\n",
    "batch_size = len(mini_train)  # Set batch size to the total number of examples to load all data at once\n",
    "# print(batch_size)\n",
    "data_loader_train = DataLoader(mini_train, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch in data_loader_train:\n",
    "    images, labels = batch\n",
    "    # Convert PyTorch tensors to NumPy arrays\n",
    "    dataset_train = images.numpy()\n",
    "    dataset_lbl_train = labels.numpy()\n",
    "    \n",
    "# print(\"Dataset train dimension:\", dataset_train.shape)\n",
    "# print(\"Labels train dimension:\", dataset_lbl_train.shape)\n",
    "# print(np.min(dataset_lbl_train))\n",
    "# print(np.max(dataset_lbl_train))\n",
    "lbls_0 = np.unique(dataset_lbl_train).tolist()\n",
    "# print(lbls_0)\n",
    "\n",
    "batch_size = len(mini_valid)  # Set batch size to the total number of examples to load all data at once\n",
    "data_loader_valid = DataLoader(mini_valid, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch in data_loader_valid:\n",
    "    images, labels = batch\n",
    "    # Convert PyTorch tensors to NumPy arrays\n",
    "    dataset_valid = images.numpy()\n",
    "    dataset_lbl_valid = labels.numpy()\n",
    "# Such that the mapping when we extend the labels works\n",
    "dataset_lbl_valid = dataset_lbl_valid + len(lbls_0)\n",
    "\n",
    "# print(np.unique(dataset_lbl_train).tolist())\n",
    "# print(np.unique(dataset_lbl_valid).tolist())\n",
    "    \n",
    "# print(\"Dataset valid dimension:\", dataset_valid.shape)\n",
    "# print(\"Labels valid dimension:\", dataset_lbl_valid.shape)\n",
    "# print(np.min(dataset_lbl_valid))\n",
    "# print(np.max(dataset_lbl_valid))\n",
    "\n",
    "batch_size = len(mini_test)  # Set batch size to the total number of examples to load all data at once\n",
    "data_loader_test = DataLoader(mini_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch in data_loader_test:\n",
    "    images, labels = batch\n",
    "    # Convert PyTorch tensors to NumPy arrays\n",
    "    dataset_test = images.numpy()\n",
    "    dataset_lbl_test = labels.numpy()\n",
    "    \n",
    "# print(\"Dataset valid dimension:\", dataset_test.shape)\n",
    "# print(\"Labels valid dimension:\", dataset_lbl_test.shape)\n",
    "# print(np.min(dataset_lbl_test))\n",
    "# print(np.max(dataset_lbl_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b48adcc",
   "metadata": {},
   "source": [
    "## Create 2 different datasets for two disjoint set of labels (deterministic for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe5509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(dataset_lbl_train)) + len(np.unique(dataset_lbl_valid))\n",
    "\n",
    "dataset_0_, dataset_0_lbl = dataset_train, dataset_lbl_train\n",
    "\n",
    "dataset_0 = dataset_0_.reshape(dataset_0_.shape[0], -1)\n",
    "dataset_0_lbl_t = torch.tensor(dataset_0_lbl)\n",
    "unique_values, counts = torch.unique(dataset_0_lbl_t, return_counts=True)\n",
    "# print(\"In train minimum and maximum amount of sample per classes in the dataset\")\n",
    "# print(\"Each classes contains at least\", torch.min(counts).item(), \"samples\")\n",
    "# print(\"Each classes contains at most\", torch.max(counts).item(), \"samples\")\n",
    "\n",
    "# print(\"Number of classes\", n_classes)\n",
    "# print(\"Shape of the dataset_0:\",dataset_0.shape)\n",
    "# print(\"Shape of the lbls\", dataset_0_lbl.shape)\n",
    "# print(\"Min label\", np.min(dataset_0_lbl))\n",
    "# print(\"Max label\", np.max(dataset_0_lbl))\n",
    "\n",
    "# dataset_1_, dataset_1_lbl = dataset_test, dataset_lbl_test\n",
    "# dataset_1 = dataset_1_.reshape(dataset_1_.shape[0], -1)\n",
    "# dataset_1_lbl_t = torch.tensor(dataset_1_lbl)\n",
    "# unique_values, counts = torch.unique(dataset_1_lbl_t, return_counts=True)\n",
    "# print(\"In train minimum and maximum amount of sample per classes in the dataset\")\n",
    "# print(\"Each classes contains at least\", torch.min(counts).item(), \"samples\")\n",
    "# print(\"Each classes contains at most\", torch.max(counts).item(), \"samples\")\n",
    "\n",
    "# print(\"Shape of the dataset_1:\",dataset_1.shape)\n",
    "# print(\"Min label\", np.min(dataset_1_lbl))\n",
    "# print(\"Max label\", np.max(dataset_1_lbl))\n",
    "\n",
    "# print(\"Some labels in set 1:\", dataset_0_lbl[0:10])\n",
    "# print(\"Some labels in set 2:\", dataset_1_lbl[0:10])\n",
    "# assert(np.all(np.isin(dataset_0_lbl, lbls_0)))\n",
    "# assert(np.all(np.isin(dataset_1_lbl, lbls_1)))\n",
    "\n",
    "# torch_dataset = torch.tensor(dataset_full_lbl)\n",
    "# unique_values, counts = torch.unique(torch_dataset, return_counts=True)\n",
    "\n",
    "# print(\"Minimum and maximum amount of sample per classes in the dataset\")\n",
    "# print(\"Each classes contains at least\", torch.min(counts).item(), \"samples\")\n",
    "# print(\"Each classes contains at most\", torch.max(counts).item(), \"samples\")\n",
    "\n",
    "dataset_valid = dataset_valid.reshape(dataset_valid.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7356d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom, rotate\n",
    "from scipy.interpolate import interp2d\n",
    "\n",
    "def rotate_dataset(dataset, angle):\n",
    "    dataset_unflatten = dataset.reshape(-1, 3, 84, 84)\n",
    "    rotated_data = rotate(dataset_unflatten, angle, axes=(2, 3), reshape=False)\n",
    "    return rotated_data.reshape(-1, 3 * 84 * 84)\n",
    "\n",
    "def zoom_dataset(dataset, zoom_factor):\n",
    "    dataset_unflatten = dataset.reshape(-1, 3, 84, 84)\n",
    "    zoomed_dataset = zoom(dataset_unflatten, (1, 1, zoom_factor, zoom_factor), order=1)\n",
    "    \n",
    "    original_size = dataset_unflatten.shape\n",
    "    zoomed_size = zoomed_dataset.shape\n",
    "    diff = int((zoomed_size[2] - original_size[2])/2)\n",
    "    interpolated_data = zoomed_dataset[:,:,diff:diff+original_size[2], diff:diff+original_size[2]]\n",
    "    return interpolated_data.reshape(-1, 3 * 84 * 84)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c4e57d",
   "metadata": {},
   "source": [
    "### Models definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaa9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet18\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, z_length):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.z_length = z_length\n",
    "        resnet18 = models.resnet18(pretrained=False)\n",
    "        resnet18.conv1 = torch.nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
    "        resnet18.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "        resnet18.fc = torch.nn.Linear(resnet18.fc.in_features, self.z_length)\n",
    "        self.resnet = resnet18\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3, 84, 84)\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ea965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ResNet12\n",
    "\n",
    "class Hypershot(nn.Module):\n",
    "    def __init__(self, kcnn_input_channels, z_length, kcnn_weights,\n",
    "                       hnet_hidden_layers, hnet_hidden_size, hnet_weights,\n",
    "                       mnet_hidden_layers, mnet_hidden_size,\n",
    "                       K, W, i_dim=28, i_cha=1, load_w = False):\n",
    "        super(Hypershot, self).__init__()\n",
    "        \n",
    "        self.kcnn_input_channels = kcnn_input_channels\n",
    "        self.z_length = z_length\n",
    "        self.kcnn_weights = kcnn_weights\n",
    "        self.hnet_hidden_layers = hnet_hidden_layers\n",
    "        self.hnet_hidden_size = hnet_hidden_size\n",
    "        self.hnet_weights = hnet_weights\n",
    "        self.mnet_hidden_layers = mnet_hidden_layers\n",
    "        self.mnet_hidden_size = mnet_hidden_size\n",
    "        \n",
    "        # Images dimension\n",
    "        self.i_dim = i_dim\n",
    "        self.i_cha = i_cha\n",
    "        \n",
    "        self.K = K\n",
    "        self.W = W\n",
    "        self.kernel = None\n",
    "        self.z_space = None\n",
    "        \n",
    "        # self.kcnn = ResNet12(output_size=z_length, hidden_size=64, channels=self.kcnn_input_channels, dropblock_dropout=0, avg_pool=False)\n",
    "        self.kcnn = ResNet(z_length=self.z_length)\n",
    "        self.mnet = MLP(n_in=W, n_out=W, hidden_layers=self.mnet_hidden_layers * [self.mnet_hidden_size])\n",
    "        # K**2 is the size of the kernel\n",
    "        self.hnet = HMLP(self.mnet.param_shapes, uncond_in_size=W**2, cond_in_size=0, \\\n",
    "                         layers = self.hnet_hidden_layers * [self.hnet_hidden_size],\\\n",
    "                         num_cond_embs=0)\n",
    "        self.hnet.apply_hyperfan_init(mnet=self.mnet)\n",
    "        \n",
    "        if load_w:\n",
    "            hnet.load_state_dict(torch.load(self.hnet_weights))\n",
    "            kcnn.load_state_dict(torch.load(self.kcnn_weights))\n",
    "            \n",
    "    \n",
    "    def compute_kernel(self, X, y):\n",
    "        \"\"\"\n",
    "        Compute Hypershot kernel for a support set X and label y\n",
    "        It takes the average of the z's for each label as suggested in the Hypershot paper\n",
    "\n",
    "        Args:\n",
    "            X (tensor): Support set used to compute the kernel\n",
    "            y (tensor): corresponding labels\n",
    "\n",
    "        Returns:\n",
    "            type: embeddings, kernel\n",
    "        \"\"\"\n",
    "        # Obtain the indices that would sort y_test\n",
    "        indices = torch.argsort(y)\n",
    "\n",
    "        # Use the indices to sort the rows of X_test\n",
    "        sorted_X = X[indices].to(device)\n",
    "        sorted_y = y[indices].to(device)\n",
    "\n",
    "        reshaped_X = sorted_X.view(sorted_X.shape[0], self.i_cha, self.i_dim, self.i_dim).to(device)\n",
    "        nn_X = self.kcnn(reshaped_X)\n",
    "        \n",
    "        mean_X = torch.zeros((int(nn_X.shape[0] / self.K), nn_X.shape[1])).to(device)\n",
    "        for i in range(self.W):\n",
    "            mean_X[i] = torch.mean(nn_X[i*self.K:(i+1)*self.K], dim = 0)\n",
    "        norm_mean_X = F.normalize(mean_X, p=2, dim=1)\n",
    "        \n",
    "        assert(nn_X.shape==(sorted_X.shape[0], self.z_length))\n",
    "        \n",
    "        return norm_mean_X, torch.matmul(norm_mean_X, torch.t(norm_mean_X)) \n",
    "\n",
    "    def get_s_and_q_sets(self, X, y, trgt_lbls, q_size):\n",
    "        \"\"\"\n",
    "        Computes a support set for data X for classes in y with K sample per classes\n",
    "        and corresponding query sets of size q_size.\n",
    "\n",
    "        Args:\n",
    "            X (tensor): Data used to compute the sets (can contain label you do not want for your sets)\n",
    "            y (tensor): corresponding labels\n",
    "            trgt_lbls : the labels that end up in the sets\n",
    "            q_size: amount of sample per classes in query set\n",
    "\n",
    "        Returns:\n",
    "            type: support set, support set labels, query set, query set labels\n",
    "        \"\"\"\n",
    "        s_set = np.zeros((len(trgt_lbls) * self.K, X.shape[1]))\n",
    "        s_set_lbl = np.zeros((len(trgt_lbls) * self.K))\n",
    "\n",
    "        q_set = np.zeros((len(trgt_lbls) * q_size, X.shape[1]))\n",
    "        q_set_lbl = np.zeros((len(trgt_lbls) * q_size))\n",
    "        r_s = [random.randint(0, 500) for _ in range(self.K)]\n",
    "        r_q = [random.randint(0, 500) for _ in range(q_size)]\n",
    "        for j, l in enumerate(trgt_lbls):\n",
    "            mask = (y == l)\n",
    "            masked_data = X[mask]\n",
    "            masked_lbls = y[mask]\n",
    "            s_set[j*self.K:(j+1)*self.K] = masked_data[r_s]\n",
    "            s_set_lbl[j*self.K:(j+1)*self.K] = masked_lbls[r_s]\n",
    "            q_set[j*q_size:(j+1)*q_size] = masked_data[r_q]\n",
    "            q_set_lbl[j*q_size:(j+1)*q_size] = masked_lbls[r_q]\n",
    "\n",
    "        s_set = torch.tensor(s_set, requires_grad=True).to(device).float()\n",
    "        s_set_lbl = torch.tensor(s_set_lbl, requires_grad=True).to(device).float()\n",
    "        q_set = torch.tensor(q_set, requires_grad=True).to(device).float()\n",
    "        q_set_lbl = torch.tensor(q_set_lbl, requires_grad=True).to(device).float()\n",
    "        \n",
    "        return s_set, s_set_lbl, q_set, q_set_lbl\n",
    "\n",
    "    def get_q_sample_features(self, X):\n",
    "        \"\"\"\n",
    "        Computes the final features used for classification, given a query sample X\n",
    "\n",
    "        Args:\n",
    "            X (tensor): query sample \n",
    "\n",
    "        Returns:\n",
    "            type: final features use by the main network\n",
    "        \"\"\"\n",
    "        X = X.view(-1, self.i_cha, self.i_dim, self.i_dim)\n",
    "        zs_q = self.kcnn(X)\n",
    "        zs_q = F.normalize(zs_q, p=2, dim=1)\n",
    "        zs_q_m = torch.matmul(self.z_space, torch.t(zs_q))\n",
    "        return torch.t(zs_q_m)\n",
    "\n",
    "    def compute_sets_and_features(self, X, y, trgt_lbls, q_size, update_kernel):\n",
    "        \"\"\"\n",
    "        Computes support and query sets given a list of labels. It can update the kernel directly if desired.\n",
    "\n",
    "        Args:\n",
    "            X (tensor): data\n",
    "            y (tensor): data labels\n",
    "            trgt_lbls : the labels that will be contained inside the returned sets\n",
    "            q_size : query set's amount of sample per label\n",
    "            update_kernel (bool) : if we want to update the hypershot kernel and z space directly\n",
    "\n",
    "        Returns:\n",
    "            type: final features use by the main network\n",
    "        \"\"\"\n",
    "        s_set, s_set_lbl, q_set, q_set_lbl = self.get_s_and_q_sets(X, y, trgt_lbls, q_size)\n",
    "        \n",
    "        z_space, kernel = self.compute_kernel(s_set, s_set_lbl)\n",
    "        if update_kernel:\n",
    "            self.z_space = z_space\n",
    "            self.kernel = kernel\n",
    "            \n",
    "        return s_set, s_set_lbl, q_set, q_set_lbl\n",
    "\n",
    "    def extend_pred_to_nclasses(self, pred, n_c, lbls):\n",
    "        out = torch.zeros((pred.shape[0], n_c)).to(device)\n",
    "        int_lbls = [int(x) for x in lbls]\n",
    "        for i in range(out.shape[0]):\n",
    "            out[i][int_lbls] = pred[i]\n",
    "        return out\n",
    "    \n",
    "    def update_kernel(s_set, s_set_lbl):\n",
    "        z_space, kernel = self.compute_kernel(s_set, s_set_lbl)\n",
    "        self.z_space = z_space\n",
    "        self.kernel = kernel\n",
    "    \n",
    "    def forward(self, x):\n",
    "        q_features = self.get_q_sample_features(x)\n",
    "        W = self.hnet(uncond_input=self.kernel.view(1, -1))\n",
    "        P = self.mnet.forward(q_features, weights=W)\n",
    "        return P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a07c5f5",
   "metadata": {},
   "source": [
    "### Accuracy computation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdcd4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_lbls(X_test, y_test, test_classes, hs, n_c, q_size):\n",
    "    \"\"\"\n",
    "    Computes the prediction accuracy for the sample with label test_classes in X_test.\n",
    "    Mainly used as utility for the calc_accuracy function below.\n",
    "    \n",
    "    Args:\n",
    "        X_test (tensor): entire test set\n",
    "        y_test (tensor): corresponding labels\n",
    "        test_classes: the classes we want to consider for testing accuracies (should contain Ks classes)\n",
    "        hs : hypershot model\n",
    "        n_c: number of classes in the entire dataset\n",
    "        q_size : query set's amount of sample per label\n",
    "\n",
    "    Returns:\n",
    "        type: accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        s_set_test, s_set_lbl_test, q_set_test, q_set_lbl_test = \\\n",
    "        hs.compute_sets_and_features(X_test, y_test, test_classes, q_size, True)\n",
    "\n",
    "        p = hs.forward(q_set_test)\n",
    "        prediction_extended_acc = hs.extend_pred_to_nclasses(p, n_c, test_classes)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(prediction_extended_acc, q_set_lbl_test.long())\n",
    "        accuracy = (torch.argmax(prediction_extended_acc,dim=1) == q_set_lbl_test.long()).float().mean().item()\n",
    "        # print(\"Correctly predicted samples had labels:\", all_q_features_lbls[torch.argmax(prediction_extended_acc,dim=1) == all_q_features_lbls.long()])\n",
    "    return round(accuracy, 2), round(loss.item(), 2)\n",
    "\n",
    "\n",
    "def calc_accuracy(X_test, y_test, hs, n_c, q_size):\n",
    "    \"\"\"\n",
    "    Computes the prediction accuracy for the entire X_test test set.\n",
    "    \n",
    "    Args:\n",
    "        X_test (tensor): entire test set\n",
    "        y_test (tensor): corresponding labels\n",
    "        hs : hypershot model\n",
    "        n_c: number of classes in the entire dataset\n",
    "        q_size : query set's amount of sample per label\n",
    "\n",
    "    Returns:\n",
    "        average accuracy and loss\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(X_test):\n",
    "        X_test_t = torch.FloatTensor(X_test).to(device)\n",
    "    else:  \n",
    "        X_test_t = torch.clone(X_test)\n",
    "        \n",
    "    if not torch.is_tensor(y_test):\n",
    "        y_test_t = torch.FloatTensor(y_test).to(device)\n",
    "    else:\n",
    "        y_test_t = torch.clone(y_test)\n",
    "        \n",
    "    diff_classes = torch.unique(y_test_t)\n",
    "    n_diff_classes = diff_classes.shape[0]\n",
    "    n_sets = int(n_diff_classes / hs.W)\n",
    "    acc, loss = 0.0, 0.0\n",
    "    for i in range(n_sets):\n",
    "        lbls = diff_classes[i*hs.W:(i+1)*hs.W].tolist()\n",
    "        # print(\"Looking at classes in acc cal\", lbls)\n",
    "        # print(\"Using y_test_t\", y_test_t)\n",
    "        d_acc, d_loss = calc_accuracy_lbls(X_test, y_test, lbls, hs, n_c, q_size)\n",
    "        acc += d_acc\n",
    "        loss += d_loss\n",
    "    acc = acc / n_sets\n",
    "    loss = loss / n_sets\n",
    "    return round(acc,2), round(loss, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3f44cd",
   "metadata": {},
   "source": [
    "### Adversarial accuracy computation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120adb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_lbls_adv(q_set_test, q_set_lbl_test, test_classes, hs, n_c):\n",
    "    \"\"\"\n",
    "    Compute accuracy for a given query test set. We assume the kernel and the z_space of the given hypershot\n",
    "    model hs to be set accordingly. \n",
    "    \n",
    "    \"\"\"\n",
    "    hs.eval()\n",
    "    p = hs.forward(q_set_test)\n",
    "    prediction_extended_acc = hs.extend_pred_to_nclasses(p, n_c, test_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(prediction_extended_acc, q_set_lbl_test.long())\n",
    "    accuracy = (torch.argmax(prediction_extended_acc,dim=1) == q_set_lbl_test.long()).float().mean().item()\n",
    "    # print(\"Correctly predicted samples had labels:\", all_q_features_lbls[torch.argmax(prediction_extended_acc,dim=1) == all_q_features_lbls.long()])\n",
    "    return round(accuracy, 2), round(loss.item(), 2)\n",
    "\n",
    "def calc_accuracy_adv_helper(X_test, y_test, test_classes, hs, n_c, q_size, pgd):\n",
    "    \"\"\"\n",
    "    Compute a support set and a query set for some given test classes. Only used within calc_accuracy_adv\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Updating the kernel here\n",
    "    s_set_test, s_set_lbl_test, q_set_test, q_set_lbl_test = \\\n",
    "    hs.compute_sets_and_features(X_test, y_test, test_classes, q_size, True)\n",
    "\n",
    "    unique_values = torch.unique(q_set_lbl_test.long())\n",
    "    value_to_index = {value.item(): index for index, value in enumerate(unique_values)}\n",
    "    q_set_lbl_test_m = torch.FloatTensor([value_to_index[value.item()] for value in q_set_lbl_test.long()])\n",
    "\n",
    "    adv_inputs = 255.0 * pgd_attack(q_set_test / 255.0, q_set_lbl_test_m.long())\n",
    "\n",
    "    p = hs.forward(adv_inputs)\n",
    "    prediction_extended_acc = hs.extend_pred_to_nclasses(p, n_c, test_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(prediction_extended_acc, q_set_lbl_test.long())\n",
    "    accuracy = (torch.argmax(prediction_extended_acc,dim=1) == q_set_lbl_test.long()).float().mean().item()\n",
    "    # print(\"Correctly predicted samples had labels:\", all_q_features_lbls[torch.argmax(prediction_extended_acc,dim=1) == all_q_features_lbls.long()])\n",
    "    return accuracy, loss.item()\n",
    "\n",
    "def calc_accuracy_adv(X_test, y_test, hs, n_c, q_size, pgd):\n",
    "    \"\"\"\n",
    "    Computes the prediction accuracy for the entire X_test test set applying PGD.\n",
    "    \n",
    "    Args:\n",
    "        X_test (tensor): test set\n",
    "        y_test (tensor): corresponding labels\n",
    "        hs : hypershot model\n",
    "        n_c: number of classes in the entire dataset\n",
    "        q_size : query set's amount of sample per label\n",
    "        pgd : a pgd attack from torchattacks\n",
    "\n",
    "    Returns:\n",
    "        type: average accuracy and loss\n",
    "    \"\"\"\n",
    "    hs.eval()\n",
    "    if not torch.is_tensor(X_test):\n",
    "        X_test_t = torch.FloatTensor(X_test).requires_grad_(True).to(device)\n",
    "    else:  \n",
    "        X_test_t = torch.clone(X_test).requires_grad_(True)\n",
    "        \n",
    "    if not torch.is_tensor(y_test):\n",
    "        y_test_t = torch.FloatTensor(y_test).requires_grad_(True).to(device)\n",
    "    else:\n",
    "        y_test_t = torch.clone(y_test).requires_grad_(True)\n",
    "        \n",
    "    diff_classes = torch.unique(y_test_t)\n",
    "    n_diff_classes = diff_classes.shape[0]\n",
    "    n_sets = int(n_diff_classes / hs.W)\n",
    "    acc, loss = 0.0, 0.0\n",
    "    for i in range(n_sets):\n",
    "        lbls = diff_classes[i*hs.W:(i+1)*hs.W].tolist()\n",
    "        d_acc, d_loss = calc_accuracy_adv_helper(X_test, y_test, lbls, hs, n_c, q_size, pgd)\n",
    "        acc += d_acc\n",
    "        loss += d_loss\n",
    "    acc = acc / n_sets\n",
    "    loss = loss / n_sets\n",
    "    return round(acc,2), round(loss, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4014d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Configure training.\n",
    "# We used 100 for training with adversarial querying and K = 5\n",
    "# We used 50 for training with adversarial querying and K = 1\n",
    "# Increasing this would be very likely to improve the scores we obtained substantially\n",
    "nepochs=50\n",
    "\n",
    "# Epoch after which adversarial training starts\n",
    "# To disable adversarial training, we can put a number higher than nepochs\n",
    "# We used 50 for training with adversarial and K = 5\n",
    "# We used 20 for training with adversarial querying and K = 1\n",
    "# Increasing this would be very likely to improve the scores we obtained substantially\n",
    "do_adv_train = 20\n",
    "\n",
    "# K-shot W-way\n",
    "# We can change the value for K as we want (tested for 1 and 5)\n",
    "K = 1\n",
    "W = 5\n",
    "\n",
    "# Epsilon parameter of the PGD attack\n",
    "# Here this will be the maximum epislon, we gradually increase it during training\n",
    "eps = 8.0 / 255\n",
    "\n",
    "# Length of the embeddings produced by the CNN (Hypershot parameter)\n",
    "z_len = 256\n",
    "\n",
    "load_weights = 0\n",
    "continue_training = 0\n",
    "\n",
    "# Amount of sample in query sets during training (for one corresponding support set)\n",
    "q_train = 15\n",
    "# Amount of sample in query sets during validation and testing (for one corresponding support set)\n",
    "q_test = 15\n",
    "\n",
    "# Factor to sample more or less training support sets per epoch. The total will be 12 * m\n",
    "m = 5\n",
    "\n",
    "# Loop in case we want to do statistics (not sued for now)\n",
    "for o in range(1):\n",
    "    print(\"Iteration\", o+1)\n",
    "    \n",
    "    # If we want to train the model for some more epochs\n",
    "    if continue_training == 0:\n",
    "        hypershot = Hypershot(kcnn_input_channels=1, z_length=z_len, kcnn_weights=None,\n",
    "                              hnet_hidden_layers=1, hnet_hidden_size=256, hnet_weights=None,\n",
    "                              mnet_hidden_layers=1, mnet_hidden_size=128,\n",
    "                              K=K, W=W, i_dim=84, i_cha=3, load_w = False).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        n_sets = int(len(lbls_0) / W)\n",
    "    \n",
    "    # Optimizer and scheduler initialization\n",
    "    optimizer = optim.Adam(hypershot.parameters(), lr=0.0001)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=int(nepochs / 1), eta_min=0.00001)\n",
    "        \n",
    "    # Main training loop\n",
    "    for epoch in range(nepochs): # For each epoch.\n",
    "        c_eps = max(0, min(((epoch-do_adv_train) / nepochs) * eps * 2, eps))\n",
    "        print(\"current eps\", c_eps)\n",
    "        pgd_attack = PGD(hypershot, eps=c_eps, alpha=2.0 / 255, steps=5)\n",
    "        \n",
    "        \n",
    "        print(\"----------------------- Epoch\", epoch, \" -----------------------\")\n",
    "        \n",
    "        # We start by generating training and test set split\n",
    "        train_test_sets = []\n",
    "        # all_test_sets = np.empty((0, dataset_0.shape[1]))\n",
    "        # all_test_sets_lbl = np.empty((0))\n",
    "        print(n_sets)\n",
    "        for l_set_id in range(m * n_sets):\n",
    "            r_lbls = random.sample(lbls_0, W)\n",
    "            r_lbls.sort()\n",
    "            if (l_set_id+1) % 10 == 0:\n",
    "                print(\"Generated train-test split for\", l_set_id+1,\"/\",m * n_sets)\n",
    "            mask_b = np.isin(dataset_0_lbl, np.array(r_lbls))\n",
    "            dataset_0_b, dataset_0_lbl_b = dataset_0[mask_b], dataset_0_lbl[mask_b]\n",
    "            dataset_0_train, dataset_0_test, dataset_0_lbl_train, dataset_0_lbl_test = \\\n",
    "                            train_test_split(dataset_0_b, dataset_0_lbl_b, random_state=42, test_size=0.05, stratify=dataset_0_lbl_b)\n",
    "            train_test_sets.append((dataset_0_train, dataset_0_test, dataset_0_lbl_train, dataset_0_lbl_test, r_lbls))\n",
    "            \n",
    "            # all_test_sets = np.concatenate((all_test_sets, dataset_0_test), axis=0)\n",
    "            # all_test_sets_lbl = np.concatenate((all_test_sets_lbl, dataset_0_lbl_test), axis=0)\n",
    "            train_test_sets.append((dataset_0_train, dataset_0_test, dataset_0_lbl_train, dataset_0_lbl_test, r_lbls))\n",
    "        \n",
    "        # Stores the loss over all labels sets\n",
    "        global_loss = 0.0\n",
    "        global_loss_float = 0.0\n",
    "        \n",
    "        # We loop over all our sets at each epoch\n",
    "        for l_set_id in range(m * n_sets):\n",
    "            if (l_set_id + 1) % 10 == 0:\n",
    "                print(\"Went over\", l_set_id+1, \"over\", n_sets * m, \"sets.\")\n",
    "            hypershot.train()\n",
    "            loss_dataset_l = 0.0\n",
    "            (dataset_l_train, dataset_l_test, dataset_l_lbl_train, dataset_l_lbl_test, c_lbls) = train_test_sets[l_set_id]\n",
    "            \n",
    "            # This also modifies the kernel and z_space of hypershot\n",
    "            s_set_train, s_set_lbl_train, q_set_train, q_set_lbl_train = \\\n",
    "            hypershot.compute_sets_and_features(dataset_l_train, dataset_l_lbl_train, c_lbls, q_train, True)\n",
    "            \n",
    "            # Formward pass\n",
    "            dataset_l_P = hypershot.forward(q_set_train)\n",
    "            prediction_extended = hypershot.extend_pred_to_nclasses(dataset_l_P, n_classes, c_lbls)\n",
    "            loss_dataset_l += criterion(prediction_extended, q_set_lbl_train.long())\n",
    "\n",
    "            # Adversarial training\n",
    "            if epoch == do_adv_train and l_set_id == 0:\n",
    "                print(\"Adversarial training starts.\")\n",
    "            if epoch >= do_adv_train:\n",
    "                unique_values = torch.unique(q_set_lbl_train.long())\n",
    "                value_to_index = {value.item(): index for index, value in enumerate(unique_values)}\n",
    "                q_set_lbl_train_m = torch.tensor([value_to_index[value.item()] for value in q_set_lbl_train.long()])\n",
    "\n",
    "                adv_inputs = 255 * pgd_attack(q_set_train / 255.0, q_set_lbl_train_m.long())\n",
    "                if l_set_id == 0:\n",
    "                    print(\"Norm of pgd\", torch.norm(adv_inputs-q_set_train))\n",
    "                adv_outputs = hypershot.forward(adv_inputs)\n",
    "                prediction_extended_adv = hypershot.extend_pred_to_nclasses(adv_outputs, n_classes, c_lbls)\n",
    "                adv_loss = criterion(prediction_extended_adv, q_set_lbl_train.long())\n",
    "                loss_dataset_l += adv_loss\n",
    "            \n",
    "            global_loss += loss_dataset_l\n",
    "            global_loss_float += loss_dataset_l.item()\n",
    "            \n",
    "            # Notice that the train_metrics and the train_metrics_adv are not computed on the same data, hence it is expected\n",
    "            # to have no relationship between them during training.\n",
    "            if l_set_id % 10 == 0:\n",
    "                train_metrics = calc_accuracy(dataset_l_train, dataset_l_lbl_train, hypershot, n_classes, q_train)\n",
    "                # test_metrics = calc_accuracy(dataset_l_test, dataset_l_lbl_test, hypershot, n_classes, q_test)\n",
    "                print(\"Local train acc and loss at the end of set:\", l_set_id, \"-->\", train_metrics)\n",
    "                # print(\"Local valid acc and loss at the end of set:\", l_set_id, \"-->\", test_metrics)\n",
    "                \n",
    "                # Training loss when attacking query image only\n",
    "                unique_values = torch.unique(q_set_lbl_train.long())\n",
    "                value_to_index = {value.item(): index for index, value in enumerate(unique_values)}\n",
    "                q_set_lbl_train_m = torch.tensor([value_to_index[value.item()] for value in q_set_lbl_train.long()])\n",
    "\n",
    "                adv_inputs_train = 255 * pgd_attack(q_set_train / 255.0, q_set_lbl_train_m.long())\n",
    "                train_metrics_adv = calc_accuracy_lbls_adv(adv_inputs_train, q_set_lbl_train.long(), c_lbls, hypershot, n_classes)\n",
    "                print(\"Local adv train acc and loss (train kernel, q attacked only):\", l_set_id, \"-->\", train_metrics_adv)\n",
    "\n",
    "                # Validation loss when attacking query image only\n",
    "                # We update the kernel here (but we did not attack the support set)\n",
    "                # s_set_test, s_set_lbl_test, q_set_test, q_set_lbl_test = \\\n",
    "                # hypershot.compute_sets_and_features(dataset_l_test, dataset_l_lbl_test, c_lbls, q_test, True)\n",
    "\n",
    "                # unique_values = torch.unique(q_set_lbl_test.long())\n",
    "                # value_to_index = {value.item(): index for index, value in enumerate(unique_values)}\n",
    "                # q_set_lbl_test_m = torch.tensor([value_to_index[value.item()] for value in q_set_lbl_test.long()])\n",
    "\n",
    "                # adv_inputs_test = pgd_attack(q_set_test, q_set_lbl_test_m.long())\n",
    "                # test_metrics_adv = calc_accuracy_lbls_adv(adv_inputs_test, q_set_lbl_test.long(), c_lbls, hypershot, n_classes)\n",
    "                # print(\"Local adv valid acc and loss (valid kernel, q attacked only):\", l_set_id, \"-->\", test_metrics_adv)\n",
    "                print(\"----\")\n",
    "\n",
    "            loss_dataset_l.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        scheduler.step()                \n",
    "  \n",
    "        print(\"Global loss at the end of epoch:\", epoch, \":\", global_loss_float)\n",
    "        if (epoch+1) % 1 == 0:\n",
    "            # (gva, gvl) = calc_accuracy(all_test_sets, all_test_sets_lbl, hypershot, n_classes, q_test)\n",
    "            (gta, gtl) = calc_accuracy(dataset_valid, dataset_lbl_valid, hypershot, n_classes, q_test)\n",
    "            # print(\"--> Global valid accuracy after epoch:\", epoch, \"-->\", gva)\n",
    "            print(\"--> Global test accuracy after epoch:\", epoch, \"-->\", gta)\n",
    "            # (gva_adv, gvl_adv) = calc_accuracy_adv(all_test_sets, all_test_sets_lbl, hypershot, n_classes, q_test, pgd_attack)\n",
    "            (gta_adv, gtl_adv) = calc_accuracy_adv(dataset_valid, dataset_lbl_valid, hypershot, n_classes, q_test, pgd_attack)\n",
    "            # print(\"--> Global adv valid accuracy after epoch:\", epoch, \"-->\", gva_adv)\n",
    "            print(\"--> Global adv test accuracy after epoch:\", epoch, \"-->\", gta_adv)\n",
    "            current_time = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "            gta_r = round(gta, 2)\n",
    "            gta_str = str(gta_r).replace('.', '_')\n",
    "            gta_r_adv = round(gta_adv, 2)\n",
    "            gta_str_adv = str(gta_r_adv).replace('.', '_')\n",
    "            hs_file = f'models/HS_{K}Shot_{W}Way_{int(eps*255)}eps_{gta_str}Acc_{gta_str_adv}Adv_{current_time}_{epoch}.pth'\n",
    "            torch.save(hypershot.state_dict(), hs_file)\n",
    "        print()\n",
    "\n",
    "    print(\"END OF ITERATION:\",o+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd33649",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "# Create a file name with the current time\n",
    "hnet_file = f'models/hnet_{current_time}_best.pth'\n",
    "torch.save(hnet.state_dict(), hnet_file)\n",
    "kcnn_file = f'models/kcnn_{current_time}_best.pth'\n",
    "torch.save(kcnn.state_dict(), kcnn_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145607b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_adv_dataset_1 = pgd_attack_data(dataset_1, dataset_1_lbl, mnet, hnet, z_space_1, K_1, 1)\n",
    "# x_adv_dataset_1_np = x_adv_dataset_1.detach().cpu().numpy()\n",
    "# x_adv_dataset_0_test = pgd_attack_data(dataset_0_test, dataset_0_lbl_test, mnet, hnet, z_space, K, 0)\n",
    "# x_adv_dataset_0_test_np = x_adv_dataset_0_test.detach().cpu().numpy()\n",
    "\n",
    "print(calc_accuracy(all_test_sets, all_test_sets_lbl, hnet, mnet, Ks, kcnn, n_classes, 5))\n",
    "print(calc_accuracy(dataset_1, dataset_1_lbl, hnet, mnet, Ks, kcnn, n_classes, 5))\n",
    "# accuracies_dataset_0_adv.append((calc_accuracy(x_adv_dataset_0_test_np, dataset_0_lbl_test, mnet, W_dataset_0)).detach().cpu())\n",
    "# accuracies_dataset_1_adv.append((calc_accuracy(x_adv_dataset_1_np, dataset_1_lbl, mnet, W_dataset_1)).detach().cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
